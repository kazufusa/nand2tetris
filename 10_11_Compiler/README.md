# Compiler I

## Compilation Engine

> ### 10.1.4 Parser
> A parser is an agent that operates according to a given grammar.
> the parser accepts as input a stream of tokens and attempts to produce aas output the parse tree associated with the given input.
> In our case, the input is expected to be structured according to the Jack grammar, and the output is written in XML.
> Note, though, that the parsing techniques that we now turn to describe are applicable to handling any programming language and structured file format.
> There are several algorithms for constructing parse trees.
> The top-down approach, also known as *recursive descent parsing*, attempts to parse the tokenized input recursively, using the nested structures admitted by the language grammar.
> Such an algorithm can be implemented as follows.
> For every nontrivial rule in the grammar, we equip the parser program with a routines designed to parse the input according to that rule.
> For example, the grammar listed in figure 10.3 can be implemented using a set of routine naamed compileStatement, compileStatements, compileLet, compileIf, ..., compileExpression, and so on.
> ..
> ### 10.3 Implementation
> The previous section specified what a syntax analyzer should do, with few implementation insights.
> This section describes *how* to build such an analyzer.
> Our proposed implementation is based on three modules:
> - JackAnalyzer: main program that sets up and invokes the other modules
> - JackTokenizer: tokenizer
> - CompilationEngine: recursive top-down parser
>
> #### The CompilationEngine
> The CompilationEngine is the backbone module of both the syntax analyzer described in this chapter and
> the full-scale compiler described in the next chapter.
> In the syntax analyzer, the compilation engine emits a structured representation of the input source code
> wrapped in XML tags.
> In the compiler, the compilation engine will instead emit eecutable VM code.
> In both versions, the parsing logic and API presented below area exactly the same.
>
> The compilation engine gets its input from a JackTokenizer and emits its output to an output file.
> The output is generated by a series of compilexxx routines, each designed to handle the compilation of a specific
> Jack language construct xxx.
> The construct between these routines is that each compilexxx routine should get from the input, and handle, all the
> tokens that mark up xxx, advance the tokenizer exactly beyond these tokens, and output the parsing of xxx.
> As a rule, each compilexxx routine is called only if the current token is xxx.
>
> #### Grammar rules that have no corresponding compilexxx routines:
> type, className, subroutineName, varName, statement, subroutineCall.
> We introduced these rules to make the Jack grammar more structed.
> As it turns out, the parsing logic of these rules is better handled by the routines that implement
> the rules that refer to them.
> For example, instead of writing a compileType routine, whenever type is mentioned in some rule xxx,
> the parsing of the possible types should be done directly by the compilexxx routine.
>
> #### Token lookahead:
> Jack is almost an LL(1) language: the current token is sufficient for determining which CompilationEngine routine to call next.
> The only exception occures when parsing a term, which occures only when parsing an expression.
> To illustrate, consider the contrived yet valid expression `y + arr[5] - p.get(row) * count() - Math.sqrt(dist) / 2`.
> This expression is made up of six terms: the variable y, the array element arr[5], the method call on the p object p.get(row), the method call on the this object count(), the call to the function (static method) Math.sqrt(dist), and the constant 2.
> Suppose that we are parsing this expression and the current token is one of the identifiers y, arr, p, count, or Math.
> In each one of these cases, we know that we have a term that begins with an identifier, but we don't known which parsing possibility to follow next.
> That's the bad news; the good news is that a single lookahead to the next token is all that we need to settle the dilemma.

# Compiler II

## 11.1.1 Handling Variables

The followings are the types of variables.

- static
    - Class variable
- field
    - Class field variable
- local
    - variables declared in Subroutine
- argument
    - arguments of Subroutine

> All we have to do now is map Jack static variables on static 0, static 1, static 2, ...; field variables on this 0, this 1, ...; local variables on local 0, local 1, ...; and argument variables on argument 0, argument 1, ....
> The subsequent mapping of the virtual memory seguments on the host RAM, as well as the intricate management of their run-time life cycles, are completely taken care of by VM implementation.
> The only thing required from the compiler is mapping the high-level variables onto the virtual memory segments.
> An important feature of high-level languages is separate namespaces:
> Jack compilers can realize the scope abstraction by managing two separate symbol tables,
> The scopes are nested, with inner scopes hiding outer ones.

### Handling variable declarations

> When the Jack compiler starts compiling a class declaration, it creates a class-level symbol table and a subroutine level symbol table.
> When the Jack compiler starts compiling a subroutine (constructor, method, or function) declaration, it resets the subroutine-level symbol table.
> If the subroutine is a method, the compiler adds the row <this, className, arg, 0> to the subroutine-level symbol table (this initialization detail is explained in section 11.1.5.2 and can be ignored til then).
