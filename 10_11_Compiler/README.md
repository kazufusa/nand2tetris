# Compiler I

## Compilation Engine

> ### 10.1.4 Parser
> A parser is an agent that operates according to a given grammar.
> the parser accepts as input a stream of tokens and attempts to produce aas output the parse tree associated with the given input.
> In our case, the input is expected to be structured according to the Jack grammar, and the output is written in XML.
> Note, though, that the parsing techniques that we now turn to describe are applicable to handling any programming language and structured file format.
> There are several algorithms for constructing parse trees.
> The top-down approach, also known as *recursive descent parsing*, attempts to parse the tokenized input recursively, using the nested structures admitted by the language grammar.
> Such an algorithm can be implemented as follows.
> For every nontrivial rule in the grammar, we equip the parser program with a routines designed to parse the input according to that rule.
> For example, the grammar listed in figure 10.3 can be implemented using a set of routine naamed compileStatement, compileStatements, compileLet, compileIf, ..., compileExpression, and so on.
> ..
> ### 10.3 Implementation
> The previous section specified what a syntax analyzer should do, with few implementation insights.
> This section describes *how* to build such an analyzer.
> Our proposed implementation is based on three modules:
> - JackAnalyzer: main program that sets up and invokes the other modules
> - JackTokenizer: tokenizer
> - CompilationEngine: recursive top-down parser
>
> #### The CompilationEngine
> The CompilationEngine is the backbone module of both the syntax analyzer described in this chapter and
> the full-scale compiler described in the next chapter.
> In the syntax analyzer, the compilation engine emits a structured representation of the input source code
> wrapped in XML tags.
> In the compiler, the compilation engine will instead emit eecutable VM code.
> In both versions, the parsing logic and API presented below area exactly the same.
>
> The compilation engine gets its input from a JackTokenizer and emits its output to an output file.
> The output is generated by a series of compilexxx routines, each designed to handle the compilation of a specific
> Jack language construct xxx.
> The construct between these routines is that each compilexxx routine should get from the input, and handle, all the
> tokens that mark up xxx, advance the tokenizer exactly beyond these tokens, and output the parsing of xxx.
> As a rule, each compilexxx routine is called only if the current token is xxx.
>
> #### Grammar rules that have no corresponding compilexxx routines:
> type, className, subroutineName, varName, statement, subroutineCall.
> We introduced these rules to make the Jack grammar more structed.
> As it turns out, the parsing logic of these rules is better handled by the routines that implement
> the rules that refer to them.
> For example, instead of writing a compileType routine, whenever type is mentioned in some rule xxx,
> the parsing of the possible types should be done directly by the compilexxx routine.
>
> #### Token lookahead:
> Jack is almost an LL(1) language: the current token is sufficient for determining which CompilationEngine routine to call next.
> The only exception occures when parsing a term, which occures only when parsing an expression.
> To illustrate, consider the contrived yet valid expression `y + arr[5] - p.get(row) * count() - Math.sqrt(dist) / 2`.
> This expression is made up of six terms: the variable y, the array element arr[5], the method call on the p object p.get(row), the method call on the this object count(), the call to the function (static method) Math.sqrt(dist), and the constant 2.
> Suppose that we are parsing this expression and the current token is one of the identifiers y, arr, p, count, or Math.
> In each one of these cases, we know that we have a term that begins with an identifier, but we don't known which parsing possibility to follow next.
> That's the bad news; the good news is that a single lookahead to the next token is all that we need to settle the dilemma.
